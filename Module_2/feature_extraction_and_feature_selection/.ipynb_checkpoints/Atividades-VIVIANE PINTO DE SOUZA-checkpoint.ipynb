{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atividades\n",
    "===\n",
    "\n",
    "Essas atividade são relativas a aulas de extração de atributos e selecão de atributos. \n",
    "- Link para video: https://drive.google.com/file/d/13LLQGLt7QsjKshBXgUdJ4RVOT8N252cU/view\n",
    "- Link para apresentação: https://docs.google.com/presentation/d/1wctFgQe7TSlBEypZbVQqqsfrnpSgOeXPSO-mCJ6jIz4\n",
    "\n",
    "\n",
    "> Lembre de criar uma `virtualenv` com os `requirements.txt` do repositório.\n",
    "\n",
    "> Lembre de criar uma `kernel` do jupyter para seus desenvolvimentos\n",
    "\n",
    "> **MANTENHA** essa arquivo no local padrão do repositório. Detro da pasta **feature_extraction_and_feature_selection**.\n",
    "\n",
    "> Enviei apenas o seu notebook para correção. Não é necessário enviar nenhum outro arquivo. Siga o padrão `Atividades-<NOME-DO-ALUNO>.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Realizar a extração de atributos utilzando as técnicas Fourier e HOS nas bases de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dados de falhas em aerogeradores\n",
    "\n",
    "As orientações abaixo devem ser seguidas antes de iniciar os trabalhos\n",
    "\n",
    "> Todo os arquivos nomeados com `v000_ ... .csv` são referentes a essa base.\n",
    "\n",
    "> A classe referente ao dado está representada por uma TAG no nome do arquivo da seguinte forma: `v000_NORMAL_ ... .csv` é o dado referente a classe de funcionamento normal do gerador. A TAG `v000_SC_LI_LVL3_ ... .csv` é a classe referente a falha tipo 1 e continua. Não se preocupem com a ordem de enumeração das classes nesse momento.\n",
    "\n",
    "> Há 5 arquivos na pasta.\n",
    "\n",
    "> Utilizar as colunas a `Current_R`, `Current_S`, `Current_T` para realizar extração de atributos. Perceba que cada coluna é referente a uma sinal de corrente elétrica, portanto cada um são representados vetores de dimensões $1x50000$.\n",
    "\n",
    "> Antes de realizar a extração de atributos deve-se dividir cada sinal em 10 partes de tamanho $1x5000$. A ideia aqui é aumentar o número de amostra da base de dados por 10. Pense que cada parte é um recorte do sinal, e ao serem concatenadas retornarão o sinal original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Todas as lib que irei precisar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from feature_extraction_signal.src import feature_extraction\n",
    "from feature_selection_framework.src.feature_selection import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregue a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current_R</th>\n",
       "      <th>Current_S</th>\n",
       "      <th>Current_T</th>\n",
       "      <th>Current_hall_R</th>\n",
       "      <th>Current_hall_S</th>\n",
       "      <th>Current_hall_T</th>\n",
       "      <th>Freq_Rated</th>\n",
       "      <th>Freq_Gen</th>\n",
       "      <th>CC_bus</th>\n",
       "      <th>Power</th>\n",
       "      <th>Load</th>\n",
       "      <th>I_R_rms</th>\n",
       "      <th>I_S_rms</th>\n",
       "      <th>I_T_rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035657</td>\n",
       "      <td>-1.402470</td>\n",
       "      <td>1.414564</td>\n",
       "      <td>2.713690</td>\n",
       "      <td>2.394956</td>\n",
       "      <td>2.550505</td>\n",
       "      <td>60</td>\n",
       "      <td>59.55</td>\n",
       "      <td>210</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184284</td>\n",
       "      <td>1.188929</td>\n",
       "      <td>1.197345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.104310</td>\n",
       "      <td>-1.389744</td>\n",
       "      <td>1.478187</td>\n",
       "      <td>2.695843</td>\n",
       "      <td>2.109424</td>\n",
       "      <td>2.547956</td>\n",
       "      <td>60</td>\n",
       "      <td>59.55</td>\n",
       "      <td>210</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184284</td>\n",
       "      <td>1.188929</td>\n",
       "      <td>1.197345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.218827</td>\n",
       "      <td>-1.338842</td>\n",
       "      <td>1.618156</td>\n",
       "      <td>2.698393</td>\n",
       "      <td>2.349067</td>\n",
       "      <td>2.578549</td>\n",
       "      <td>60</td>\n",
       "      <td>59.55</td>\n",
       "      <td>210</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184284</td>\n",
       "      <td>1.188929</td>\n",
       "      <td>1.197345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.295173</td>\n",
       "      <td>-1.224312</td>\n",
       "      <td>1.579983</td>\n",
       "      <td>2.685645</td>\n",
       "      <td>2.422999</td>\n",
       "      <td>2.573450</td>\n",
       "      <td>60</td>\n",
       "      <td>59.55</td>\n",
       "      <td>210</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184284</td>\n",
       "      <td>1.188929</td>\n",
       "      <td>1.197345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.486036</td>\n",
       "      <td>-1.275214</td>\n",
       "      <td>1.809024</td>\n",
       "      <td>2.670347</td>\n",
       "      <td>2.305727</td>\n",
       "      <td>2.604043</td>\n",
       "      <td>60</td>\n",
       "      <td>59.55</td>\n",
       "      <td>210</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184284</td>\n",
       "      <td>1.188929</td>\n",
       "      <td>1.197345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Current_R  Current_S  Current_T  Current_hall_R  Current_hall_S  \\\n",
       "0   0.035657  -1.402470   1.414564        2.713690        2.394956   \n",
       "1  -0.104310  -1.389744   1.478187        2.695843        2.109424   \n",
       "2  -0.218827  -1.338842   1.618156        2.698393        2.349067   \n",
       "3  -0.295173  -1.224312   1.579983        2.685645        2.422999   \n",
       "4  -0.486036  -1.275214   1.809024        2.670347        2.305727   \n",
       "\n",
       "   Current_hall_T  Freq_Rated  Freq_Gen  CC_bus  Power  Load   I_R_rms  \\\n",
       "0        2.550505          60     59.55     210    0.1     0  1.184284   \n",
       "1        2.547956          60     59.55     210    0.1     0  1.184284   \n",
       "2        2.578549          60     59.55     210    0.1     0  1.184284   \n",
       "3        2.573450          60     59.55     210    0.1     0  1.184284   \n",
       "4        2.604043          60     59.55     210    0.1     0  1.184284   \n",
       "\n",
       "    I_S_rms   I_T_rms  \n",
       "0  1.188929  1.197345  \n",
       "1  1.188929  1.197345  \n",
       "2  1.188929  1.197345  \n",
       "3  1.188929  1.197345  \n",
       "4  1.188929  1.197345  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Como carregar a base?\n",
    "\n",
    "##Configurar a pasta de dados (data lá no dir) utilizando caminho relativo. Configuração está sendo atribuída à variável DataFolder*/\n",
    "DATAFOLDER = path.join('..', '..', 'data')\n",
    "DATAFILES = ['v000_FAULT_SC_HI_LVL2_FR6000_FG5942_L000_0,6IN_SENSORC.csv', \n",
    "             'v000_FAULT_SC_LI_LVL3_FR4500_FG4365_L000_0,8IN_SENSORC.csv', \n",
    "             'v000_FAULT_SC_LI_LVL3_FR6000_FG5927_L000_0,4IN_SENSORC.csv',\n",
    "            'v000_NORMAL_FR4500_FG4385_L000_1,0IN_SENSORC.csv',\n",
    "            'v000_NORMAL_FR6000_FG5955_L000_0,5IN_SENSORC.csv']\n",
    "SEED = 1987298712\n",
    "\n",
    "##LEITURA UTILIZANDO o PANDAS DOS NOSSOS ARQUIVOS NORMAL E FAULT CSV \n",
    "data_normal = pd.read_csv(path.join(DATAFOLDER, DATAFILES[4]))\n",
    "data_fault = pd.read_csv(path.join(DATAFOLDER, DATAFILES[2]))\n",
    "#o head() vai mostrar nossass 14 variables dos 5 sinais na tabela embaixo desse bloco!\n",
    "data_normal.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Comparativo da média do sinal e sua distribuição\n",
    "\n",
    "- Realize o calculo da média e desvio padrão em cada um dos sinais e exiba o resultado em um dataframe. Discuta suas conclusões.\n",
    "\n",
    "**help**: utilize as funcões nativas do numpy ou do pandas. Lembre que o sinal é uma senoide, qual a média em uma senoide simétrica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Média</th>\n",
       "      <th>Desvio Padrão</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.010286</td>\n",
       "      <td>1.184251e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012611</td>\n",
       "      <td>1.188874e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002357</td>\n",
       "      <td>1.197354e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.499768</td>\n",
       "      <td>1.355010e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.496935</td>\n",
       "      <td>1.350311e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.491380</td>\n",
       "      <td>1.254342e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59.550000</td>\n",
       "      <td>3.192500e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.317015e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.184284</td>\n",
       "      <td>5.662194e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.188929</td>\n",
       "      <td>1.101352e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.197345</td>\n",
       "      <td>8.915180e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Média  Desvio Padrão\n",
       "0    -0.010286   1.184251e+00\n",
       "1     0.012611   1.188874e+00\n",
       "2     0.002357   1.197354e+00\n",
       "3     2.499768   1.355010e-01\n",
       "4     2.496935   1.350311e-01\n",
       "5     2.491380   1.254342e-01\n",
       "6    60.000000   0.000000e+00\n",
       "7    59.550000   3.192500e-11\n",
       "8   210.000000   0.000000e+00\n",
       "9     0.100000   1.317015e-14\n",
       "10    0.000000   0.000000e+00\n",
       "11    1.184284   5.662194e-13\n",
       "12    1.188929   1.101352e-12\n",
       "13    1.197345   8.915180e-13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realize o calculo da média e desvio padrão em cada um dos sinais \n",
    "#inicializando listas\n",
    "media = []\n",
    "desvio_padrao = []\n",
    "\n",
    "# lista de médias e desvio padrões para cada uma das variables. VOu adicionar cada média e std do data_normal de cada i à lista desvio_padrao e media\n",
    "for i in range(14):\n",
    "    desvio_padrao.append(data_normal.std().values[i])\n",
    "    media.append(data_normal.mean().values[i])\n",
    "    \n",
    "# exiba o resultado em um dataframe\n",
    "\n",
    "m_df = pd.DataFrame(data = media, columns = ['Média'])\n",
    "std_df = pd.DataFrame(data = desvio_padrao, columns = ['Desvio Padrão'])\n",
    "\n",
    "# concatenação\n",
    "pd.concat([m_df, std_df], axis=1, join='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Extração de atributos no sinal\n",
    "\n",
    "- Utilize o código de `feature_extraction_signal` em: https://github.com/navarmn/feature_extraction_signal\n",
    "- Use as classes `Fourier` e `HOS` de maneira adequada. Lembre do método `.transform()`.\n",
    "- Na classe `Fourier`utilize os parâmetros: `fs=5000`; o valor de fundamental está na TAG do nome em `_FG5955_`significa `fundamental=59.55`. `harmonics=(0.5, 1, 1.5, 2.5, 3, 5, 7)`, mas sintam-se à vontade para buscar outras harmônicas;\n",
    "- Os rótulos devem serem impostos de acordo com a descrição da tag feita cima. \n",
    "- Monte um dataframe que contenham os atributos em cada coluna e a útlima com o rótulo. Concatene os artibutos extraídos da `Current_R`, `Current_S` e `Current_T`.\n",
    "- Deverá ser feito um dataframe para os atributos de Fourier e um para os atributos de HOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.5_R</th>\n",
       "      <th>1_R</th>\n",
       "      <th>1.5_R</th>\n",
       "      <th>2.5_R</th>\n",
       "      <th>3_R</th>\n",
       "      <th>5_R</th>\n",
       "      <th>7_R</th>\n",
       "      <th>0.5_S</th>\n",
       "      <th>1_S</th>\n",
       "      <th>1.5_S</th>\n",
       "      <th>...</th>\n",
       "      <th>3_S</th>\n",
       "      <th>5_S</th>\n",
       "      <th>7_S</th>\n",
       "      <th>0.5_T</th>\n",
       "      <th>1_T</th>\n",
       "      <th>1.5_T</th>\n",
       "      <th>2.5_T</th>\n",
       "      <th>3_T</th>\n",
       "      <th>5_T</th>\n",
       "      <th>7_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.002707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.019491</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.008741</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.006918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.003292</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.001859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>0.017829</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.004520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.003083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.5_R       1_R     1.5_R     2.5_R       3_R       5_R       7_R  \\\n",
       "0  0.001095  0.001277  0.001918  0.002628  0.002227  0.002919  0.002225   \n",
       "1  0.002822  0.003791  0.019491  0.005401  0.003715  0.004000  0.004861   \n",
       "2  0.001429  0.004262  0.003552  0.003507  0.004367  0.003292  0.003073   \n",
       "3  0.005041  0.005721  0.017829  0.010172  0.008299  0.010946  0.007722   \n",
       "4  0.001962  0.002993  0.002656  0.003446  0.002962  0.003507  0.003205   \n",
       "\n",
       "      0.5_S       1_S     1.5_S  ...       3_S       5_S       7_S     0.5_T  \\\n",
       "0  0.001408  0.002476  0.002738  ...  0.001564  0.003230  0.002526  0.002274   \n",
       "1  0.002159  0.002268  0.020921  ...  0.005281  0.007329  0.005246  0.004543   \n",
       "2  0.001102  0.004450  0.003826  ...  0.002369  0.003196  0.001750  0.001230   \n",
       "3  0.004242  0.004446  0.013907  ...  0.007882  0.007870  0.006494  0.002791   \n",
       "4  0.003298  0.006923  0.005191  ...  0.003641  0.002768  0.003440  0.002696   \n",
       "\n",
       "        1_T     1.5_T     2.5_T       3_T       5_T       7_T  \n",
       "0  0.004525  0.002392  0.002334  0.002347  0.002364  0.002707  \n",
       "1  0.007272  0.021583  0.008734  0.008741  0.008049  0.006918  \n",
       "2  0.003121  0.002720  0.003168  0.002555  0.001651  0.001859  \n",
       "3  0.003975  0.018066  0.008152  0.006263  0.005550  0.004520  \n",
       "4  0.005173  0.004397  0.003026  0.002255  0.003243  0.003083  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilize o código de feature_extraction_signal em: https://github.com/navarmn/feature_extraction_signal\n",
    "\n",
    "# ------- fourier --------\n",
    "\n",
    "fe_fourier = feature_extraction.Fourier(fs= 5000, harmonics=(0.5, 1, 1.5, 2.5, 3, 5, 7), fundamental=59.55)\n",
    "\n",
    "\n",
    "#Monte um dataframe que contenham os atributos em cada coluna e a útlima com o rótulo. \n",
    "#Concatene os artibutos extraídos da Current_R, Current_S e Current_T.\n",
    "#Deverá ser feito um dataframe para os atributos de Fourier e um para os atributos de HOS.\n",
    "#Lembre do método .transform() !!!!!!!!!\n",
    "\n",
    "#Inicializando listas r, s e t\n",
    "\n",
    "FR = []\n",
    "FS = []\n",
    "FT = []\n",
    "\n",
    "#Para cada \"i\" (datafile) dentro do no nosso DATAFILES que foi declarado láaaaa em cima:\n",
    "for datafile in DATAFILES:\n",
    "    #1. a gente vai ler, carregar os dados\n",
    "    data = pd.read_csv(path.join(DATAFOLDER, datafile))\n",
    "    #2. fazer a feature extraction \n",
    "    feature_vector_FR =  fe_fourier.transform(data['Current_R'])\n",
    "    feature_vector_FS = fe_fourier.transform(data['Current_S'])\n",
    "    feature_vector_FT = fe_fourier.transform(data['Current_T'])\n",
    "    #3. FAZER A ADIÇÃO Às LISTAs inicializadas DE CADA FEATURE EXTRAÍDA\n",
    "    FR.append(feature_vector_FR['features'])\n",
    "    FS.append(feature_vector_FS['features'])\n",
    "    FT.append(feature_vector_FT['features'])\n",
    "    \n",
    "#Monte um dataframe que contenham os atributos em cada coluna e a útlima com o rótulo.\n",
    "\n",
    "dataframe_FR = pd.DataFrame(data = FR, columns = ['0.5_R', '1_R', '1.5_R', '2.5_R', '3_R', '5_R', '7_R'])\n",
    "dataframe_FS = pd.DataFrame(data = FS, columns = ['0.5_S', '1_S', '1.5_S', '2.5_S', '3_S', '5_S', '7_S'])\n",
    "dataframe_FT = pd.DataFrame(data = FT, columns = ['0.5_T', '1_T', '1.5_T', '2.5_T', '3_T', '5_T', '7_T'])\n",
    "    \n",
    "#Concatene os artibutos extraídos da Current_R, Current_S e Current_T.\n",
    "\n",
    "#ficou meio esquisto quando compilei, portanto resolvi botar logos o R, S e T.\n",
    "\n",
    "#dataframe atributos de Fourier\n",
    "FINAL_FOURIER = pd.concat([dataframe_FR, dataframe_FS, dataframe_FT], axis=1, join='inner')\n",
    "FINAL_FOURIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rms_R</th>\n",
       "      <th>skewness_R</th>\n",
       "      <th>Kurtosis_R</th>\n",
       "      <th>Variance_R</th>\n",
       "      <th>Rms_S</th>\n",
       "      <th>skewness_S</th>\n",
       "      <th>Kurtosis_S</th>\n",
       "      <th>Variance_S</th>\n",
       "      <th>Rms_T</th>\n",
       "      <th>skewness_T</th>\n",
       "      <th>Kurtosis_T</th>\n",
       "      <th>Variance_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.295173</td>\n",
       "      <td>1.677402</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>-1.442273</td>\n",
       "      <td>1.211041</td>\n",
       "      <td>1.466524</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>-1.436841</td>\n",
       "      <td>1.249027</td>\n",
       "      <td>1.560100</td>\n",
       "      <td>0.003729</td>\n",
       "      <td>-1.439101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.148889</td>\n",
       "      <td>9.915628</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>-1.520664</td>\n",
       "      <td>2.414731</td>\n",
       "      <td>5.830991</td>\n",
       "      <td>-0.008669</td>\n",
       "      <td>-1.326985</td>\n",
       "      <td>2.460111</td>\n",
       "      <td>6.052261</td>\n",
       "      <td>-0.005396</td>\n",
       "      <td>-1.443063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.560922</td>\n",
       "      <td>2.436410</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>-1.482916</td>\n",
       "      <td>1.293480</td>\n",
       "      <td>1.672948</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>-1.361676</td>\n",
       "      <td>1.110920</td>\n",
       "      <td>1.234167</td>\n",
       "      <td>-0.002570</td>\n",
       "      <td>-1.407382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.906343</td>\n",
       "      <td>8.446975</td>\n",
       "      <td>-0.005243</td>\n",
       "      <td>-1.472242</td>\n",
       "      <td>2.920356</td>\n",
       "      <td>8.528573</td>\n",
       "      <td>-0.004661</td>\n",
       "      <td>-1.473669</td>\n",
       "      <td>2.986445</td>\n",
       "      <td>8.919035</td>\n",
       "      <td>-0.005999</td>\n",
       "      <td>-1.442528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.184284</td>\n",
       "      <td>1.402451</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>-1.446144</td>\n",
       "      <td>1.188929</td>\n",
       "      <td>1.413422</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>-1.448900</td>\n",
       "      <td>1.197345</td>\n",
       "      <td>1.433657</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>-1.443700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rms_R  skewness_R  Kurtosis_R  Variance_R     Rms_S  skewness_S  \\\n",
       "0  1.295173    1.677402    0.003296   -1.442273  1.211041    1.466524   \n",
       "1  3.148889    9.915628    0.000336   -1.520664  2.414731    5.830991   \n",
       "2  1.560922    2.436410    0.001083   -1.482916  1.293480    1.672948   \n",
       "3  2.906343    8.446975   -0.005243   -1.472242  2.920356    8.528573   \n",
       "4  1.184284    1.402451    0.005195   -1.446144  1.188929    1.413422   \n",
       "\n",
       "   Kurtosis_S  Variance_S     Rms_T  skewness_T  Kurtosis_T  Variance_T  \n",
       "0    0.006055   -1.436841  1.249027    1.560100    0.003729   -1.439101  \n",
       "1   -0.008669   -1.326985  2.460111    6.052261   -0.005396   -1.443063  \n",
       "2    0.006783   -1.361676  1.110920    1.234167   -0.002570   -1.407382  \n",
       "3   -0.004661   -1.473669  2.986445    8.919035   -0.005999   -1.442528  \n",
       "4    0.001404   -1.448900  1.197345    1.433657    0.000487   -1.443700  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- HOS --------\n",
    "fe_HOS = feature_extraction.HOS()\n",
    "\n",
    "#inicializando as listas r, s e t\n",
    "\n",
    "HR = []\n",
    "HS = []\n",
    "HT = []\n",
    "\n",
    "#Para cada \"i\" (datafile) dentro do no nosso DATAFILES que foi declarado láaaaa em cima:\n",
    "for datafile in DATAFILES:\n",
    "    #1. a gente vai ler, carregar os dados\n",
    "    data = pd.read_csv(path.join(DATAFOLDER, datafile))\n",
    "    #2. fazer a feature extraction \n",
    "    feature_vector_HR = fe_HOS.transform(data['Current_R'])\n",
    "    feature_vector_HS = fe_HOS.transform(data['Current_S'])\n",
    "    feature_vector_HT = fe_HOS.transform(data['Current_T'])\n",
    "    #3. FAZER A ADIÇÃO Às LISTAs inicializadas DE CADA FEATURE EXTRAÍDA\n",
    "    HR.append(feature_vector_HR['features'])\n",
    "    HS.append(feature_vector_HS['features'])\n",
    "    HT.append(feature_vector_HT['features'])\n",
    "    \n",
    "#Monte um dataframe que contenham os atributos em cada coluna e a útlima com o rótulo.\n",
    "\n",
    "dataframe_HR = pd.DataFrame(data = HR, columns = ['Rms_R', 'skewness_R', 'Kurtosis_R', 'Variance_R'])\n",
    "dataframe_HS = pd.DataFrame(data = HS, columns = ['Rms_S', 'skewness_S', 'Kurtosis_S', 'Variance_S'])\n",
    "dataframe_HT = pd.DataFrame(data = HT, columns = ['Rms_T', 'skewness_T', 'Kurtosis_T', 'Variance_T'])\n",
    "\n",
    "\n",
    "#Concatene os artibutos extraídos da Current_R, Current_S e Current_T.\n",
    "FINAL_HOS = pd.concat([dataframe_HR, dataframe_HS, dataframe_HT], axis=1, join='inner')\n",
    "FINAL_HOS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Análise exploratória na base criada com os extratores de atributos\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Faça um resumo do relatório, destacando os principais pontos gerados na base.\n",
    "- Faça uma análise para cada uma das bases:\n",
    "    1. Features criada com Fourier\n",
    "    2. Features criada com HOS\n",
    "    3. Combinação das duas features (Fourier + HOS). \n",
    "> Dica: dê atenção ao coeficiente de correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visions.relations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8867425d89b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\"ModuleNotFoundError: No module named 'visions.relations'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#JEOVANE DISSE QUE PODE CONTINUAR ATÉ DOMINGO, MAS DESDE SEXTA PASSADA QUE EU TÔ ENGANXADA NESSE NEGÓCIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/.data-science/lib/python3.6/site-packages/pandas_profiling/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile_report\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/.data-science/lib/python3.6/site-packages/pandas_profiling/controller/pandas_decorator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile_report\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/.data-science/lib/python3.6/site-packages/pandas_profiling/profile_report.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdescribe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdescribe_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessageType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPandasProfilingSummarizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/.data-science/lib/python3.6/site-packages/pandas_profiling/model/describe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalculate_correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicates\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/.data-science/lib/python3.6/site-packages/pandas_profiling/model/correlations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBoolean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnsupported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/.data-science/lib/python3.6/site-packages/pandas_profiling/model/typeset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvisions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIdentityRelation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInferenceRelation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvisions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnullable_series_contains\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvisions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseries_not_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'visions.relations'"
     ]
    }
   ],
   "source": [
    "# Use a ferramenta pandas-profiling https://github.com/pandas-profiling/pandas-profiling\n",
    "#AQUI EU NÃO CONSEGUI IR PRA FRENTE, VISTO QUE NÃO CONSEGUI RESOLVER O PROBLEMA QUE DEU. \n",
    "#\"ModuleNotFoundError: No module named 'visions.relations'\"\n",
    "#JEOVANE DISSE QUE PODE CONTINUAR ATÉ DOMINGO, MAS DESDE SEXTA PASSADA QUE EU TÔ ENGANXADA NESSE NEGÓCIO\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "\n",
    "profile_final_fourier = ProfileReport(FINAL_FOURIER, title='FOURIER', html={'style':{'full_width':True}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Realizar um estudo de relevância de atributos utilzando as técnicas exibidas na aula.\n",
    "\n",
    "Nesse momento utilize a base de dados `Clinical_data_09-09-19-processed.csv`. Uma breve descrição da base:\n",
    "- Contém um histórico dos registros de pacientes acometidos com uma determinada patologia.\n",
    "- Os registros são variados, vão desde resposta de questionários médicos de anamnese, por exemplo, \"*É fumante nos últimos 5 anos?*\", \"*Faz uso de álcool constantemente?*\", até resultados de exames clínicos como ECG e Ecocardiograma.\n",
    "- O rótulo dessa base é a coluna `Óbito`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregue a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como carregar a base?\n",
    "from os import path\n",
    "import pandas as pd\n",
    "\n",
    "#Configurar a pasta de dados (data lá no dir) utilizando caminho relativo. Configuração está sendo atribuída à variável DataFolder*/\n",
    "\n",
    "DATAFOLDER = path.join('..', '..', 'data')\n",
    "\n",
    "#Nesse momento utilize a base de dados Clinical_data_09-09-19-processed.csv. Uma breve descrição da base:\n",
    "\n",
    "DATAFILES = [\n",
    "        'Clinical_data_09-09-19-processed.csv'\n",
    "]\n",
    "\n",
    "resultados_exames_clinicos = ['ECG ', 'FC',\n",
    "       'Alt Prim', 'Dist Cond InterVent ', 'Dist Cond AtrioVent ',\n",
    "       'Pausa > 3s ', 'ESV', 'EV', 'TVMNS', 'Area Elet inativa']\n",
    "\n",
    "anamnese = [\n",
    "       'Cancer', 'HAS', 'DM2', 'Cardiopatia Outra',\n",
    "       'Marcapasso', 'Sincope', 'Fibrilação/Flutter Atrial', 'I R Crônica',\n",
    "       'DLP', 'Coronariopatia', 'Embolia Pulmonar', 'Ins Cardiaca ', 'AVC',\n",
    "       'DVP', 'TSH', 'Tabagismo', 'Alcoolismo', 'Sedentarismo']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paciente</th>\n",
       "      <th>Nome do Paciente</th>\n",
       "      <th>Prontuario</th>\n",
       "      <th>Date Nasc</th>\n",
       "      <th>Sexo</th>\n",
       "      <th>Nat.</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Cancer</th>\n",
       "      <th>HAS</th>\n",
       "      <th>DM2</th>\n",
       "      <th>...</th>\n",
       "      <th>Disf Diastolica</th>\n",
       "      <th>Deficit Seg</th>\n",
       "      <th>NYHA</th>\n",
       "      <th>Rassi pontos</th>\n",
       "      <th>Rassi escore</th>\n",
       "      <th>Diretriz 2005</th>\n",
       "      <th>CDI</th>\n",
       "      <th>Ablações</th>\n",
       "      <th>Amiodarona</th>\n",
       "      <th>Obito</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adão Severo de Souza</td>\n",
       "      <td>333104.0</td>\n",
       "      <td>29/11/1950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adão Severo de Souza</td>\n",
       "      <td>333104.0</td>\n",
       "      <td>29/11/1950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adão Severo de Souza</td>\n",
       "      <td>333104.0</td>\n",
       "      <td>29/11/1950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adão Severo de Souza</td>\n",
       "      <td>333104.0</td>\n",
       "      <td>29/11/1950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adão Severo de Souza</td>\n",
       "      <td>333104.0</td>\n",
       "      <td>29/11/1950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Paciente      Nome do Paciente  Prontuario  Date Nasc   Sexo Nat.  BMI   \\\n",
       "0      NaN  Adão Severo de Souza    333104.0  29/11/1950   1.0   PI    25   \n",
       "1      NaN  Adão Severo de Souza    333104.0  29/11/1950   1.0   PI    23   \n",
       "2      NaN  Adão Severo de Souza    333104.0  29/11/1950   1.0   PI    24   \n",
       "3      NaN  Adão Severo de Souza    333104.0  29/11/1950   1.0   PI    26   \n",
       "4      NaN  Adão Severo de Souza    333104.0  29/11/1950   1.0   PI    25   \n",
       "\n",
       "   Cancer  HAS  DM2  ...  Disf Diastolica  Deficit Seg  NYHA  Rassi pontos  \\\n",
       "0       0  1.0  1.0  ...                1            0     1           2.0   \n",
       "1       0  1.0  1.0  ...                1            0     1           2.0   \n",
       "2       0  1.0  1.0  ...                1            0     1           2.0   \n",
       "3       0  1.0  1.0  ...                1            0     1           2.0   \n",
       "4       0  1.0  1.0  ...                1            0     1           2.0   \n",
       "\n",
       "   Rassi escore  Diretriz 2005  CDI   Ablações  Amiodarona  Obito  \n",
       "0           1.0            1.0     0         0           0    0.0  \n",
       "1           1.0            1.0     0         0           0    0.0  \n",
       "2           1.0            1.0     0         0           0    0.0  \n",
       "3           1.0            1.0     0         0           0    0.0  \n",
       "4           1.0            1.0     0         0           0    0.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LEITURA UTILIZANDO o PANDAS DOS NOSSOS ARQUIVOS NORMAL E FAULT CSV \n",
    "data = pd.read_csv(path.join(DATAFOLDER, DATAFILES[0]))\n",
    "#visu\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Análise exploratória na base de dados\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Faça um resumo do relatório, destacando os principais pontos gerados na base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identicar qual a variáveis parecem influenciar no óbito dos pacientes :(\n",
    "- Utilize o código `feature_selection_framework` https://github.com/navarmn/feature_selection_framework \n",
    "- Monte o resultado em um `DataFrame`, as colunas serão referentes aos métodos e as linhas deverão ser os atributos. Coloque 1 quando o método indicar como relevante e 0 quando o método indicar com não relevante;\n",
    "- Utilize o seguinte critério para validar um atributo como relevante: moda >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. QUESTÃO DESAFIO\n",
    "- Essa etapa não entrará com atividade avaliativa, pois a base de dados a seguir não é tão bonita quanto parece 🤪. Há muitas etapas de pré-processamento, agrupmaento e mais importante de tudo, o usuário tem que fazer as duas tabelas `weekly-infos-before-shrink.csv` e `user-status-after-shrink.csv` conversarem entre si.\n",
    "- Fique à vontade para tentar e para tirar dúvidas. 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse momento utilize a base de dados `weekly-infos-before-shrink.csv` e `user-status-after-shrink.csv`. Uma breve descrição da base:\n",
    "- Essa base foi retirada de um serviço de streaming de midia. Os atributos são relativos a perfis de consumo de usuários.\n",
    "- O objetivo é realizar detecção de *churn* (https://resultadosdigitais.com.br/blog/o-que-e-churn/)\n",
    "- Possui um registro de 17 semanas de uso e os rótulos estáo na tabela `user-status-after-shrink.csv`, que indicam se ao final do período o usuário cancelou e se manteve assinante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Análise exploratória na base de dados\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Faça um resumo do relatório, destacando os principais pontos gerados na base.\n",
    "> Exiba a matriz de correlação!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identicar qual a variáveis parecem influenciar no cancelamento da assinatura.\n",
    "\n",
    "- Utilize o código `feature_selection_framework` https://github.com/navarmn/feature_selection_framework \n",
    "- Monte o resultado em um `DataFrame`, as colunas serão referentes aos métodos e as linhas deverão ser os atributos. Coloque 1 quando o método indicar como relevante e 0 quando o método indicar com não relevante;\n",
    "- Utilize o seguinte critério para validar um atributo como relevante: moda >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python data science",
   "language": "python",
   "name": "python-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
